import pandas as pd
import json
import difflib
from modules.sys import System

"""
    CHANNEL_FREQUENCY_THRESHOLD: This parameter configures the threshold for a channel to be considered relevant in the study, 
    channels with less frequency (precentage) than the stated here won't be considered relevant. This is used in several places 
    of the script: for the frequency of the channels in a given configuration, for the frequency of a channel in the whole 
    dataset and for the frequency of a channel in the whole dataset taking into account the equivalences found.

    CONF_GROUP_SIMILARITY_THRESHOLD: This parameter controls when two configurations (as read from the input file "channels.csv",
    generated by "parser_channels.py") are similar enough to be grouped together to imput channel equivalences later on.

    CHANNEL_EQUIVALENCE_SIMILARITY_THRESHOLD: Once two configurations are considered equivalent, we llok for the different channels 
    in the "equivalent" configurations, if this channels are similar enough (given the ratio configured in this parameter) the 
    channels are considered equivalents

    CONF_CONTRIBUTION_THRESHOLD: How much in percentage a configuration must contribute to the sample to be considered.    
"""
CHANNEL_FREQUENCY_THRESHOLD = 70
CONF_GROUP_SIMILARITY_THRESHOLD = 0.95
CHANNEL_EQUIVALENCE_SIMILARITY_THRESHOLD = 0.6
CONF_CONTRIBUTION_THRESHOLD = 0.05

system = System()
system.createDirIfNotExists("out")

with open("out/channel_freqs.txt", "w") as outfile:    
    df = pd.read_csv("out/channels.csv", header=0, names=['sub', 'session', 'count', 'channels'])

    outfile.writelines([f"Total records: {df.shape[0]}\n"])
    outfile.writelines([f"Unique configurations: {len(df['count'].unique())}: [{df['count'].unique()}]", "\n"])

    frequencies = {}
    channel_mappings = {}
    equivalent_confs = {}

    for conf in df['count'].unique():
        outfile.writelines([f"CONFIGURATION {conf} CHANNELS:", "\n"])
        common = []
        channel_mappings[str(conf)] = {}
        equivalent_confs[str(conf)] = []
        channels = df[df['count'] == conf]['channels'].unique()

        for channs in channels:
            if common:
                common = list(set(common).intersection(channs.split("|")))
            else:
                common = channs.split("|")
        
        # Try to find equivalent configurations 
        groups = {}
        for channs in channels:
            for channsInner in channels:
                if channsInner != channs:
                    res = difflib.SequenceMatcher(lambda x: x == "|", channs.lower(), channsInner.lower())
                    ratio = res.ratio()
                    if ratio > CONF_GROUP_SIMILARITY_THRESHOLD:

                        try:
                            groups[channs].append({ "item": channsInner, "ratio": ratio })
                        except KeyError:
                            groups[channs] = [{ "item": channsInner, "ratio": ratio }]

                        try:
                            groups[channsInner].append({ "item": channs, "ratio": ratio })
                        except KeyError:
                            groups[channsInner] = [{ "item": channs, "ratio": ratio }]

        # Deal with repeated groups
        for channs in channels:
            partial = {}
            for parent, group in groups.items():
                for member in group:
                    if member["item"] == channs:
                        try:
                            partial[parent].append(member)
                        except KeyError:
                            partial[parent] = [member]
            
            maxRatio = ( None, { "ratio": 0 } )
            for parent, members in partial.items():
                for member in members:
                    if member["ratio"] > maxRatio[1]["ratio"]:
                        maxRatio = [parent, member]
            
            for partialParent in partial.keys():
                if partialParent != maxRatio[0]:
                    groups[partialParent] = list(filter( lambda x: x["item"] != maxRatio[1]["item"], groups[partialParent]))

        for parent in groups.keys():
            groups[parent] = [ json.loads(i) for i in set(json.dumps(item, sort_keys=True) for item in groups[parent]) ]

        toRemove = []
        for parent in groups.keys():
            for parentInner, members in groups.items():
                for member in members:
                    if member["item"] == parent:
                        if len(members) > len(groups[parent]):
                            toRemove.append(parent)
                        else:
                            toRemove.append(parentInner)

        for parent in list(set(toRemove)):
            del groups[parent]

        # Store channel differences between allegedly equivalent configurations
        gdiff = {}
        for parent, group in groups.items():
            gdiff[parent] = {}
            
            for member in group:
                parentSet = set(parent.split("|"))
                memberSet = set(member["item"].split("|"))
                intersection = parentSet.intersection(memberSet)

                gdiff[parent][member["item"]] = { "member": list(memberSet - intersection), "parent": list(parentSet - intersection) }

        # Given the differences found in equivalent configurations, try to guess a channel mapping for each configuration
        for parent, group in gdiff.items():
            for item, results in group.items():
                memberArray = results["member"]
                parentArray = results["parent"]

                for extraMember in memberArray:
                    for extraParent in parentArray:
                        if extraMember != extraParent: 
                            res = difflib.SequenceMatcher(None, extraMember.lower(), extraParent.lower())
                            ratio = res.ratio()

                            if ratio > CHANNEL_EQUIVALENCE_SIMILARITY_THRESHOLD:
                                if extraParent in channel_mappings[str(conf)]:
                                    if extraMember not in channel_mappings[str(conf)][extraParent]:
                                        channel_mappings[str(conf)][extraParent].append(extraMember)
                                else:
                                    channel_mappings[str(conf)][extraParent] = [extraMember]

                                if extraMember in channel_mappings[str(conf)]:
                                    if extraParent not in channel_mappings[str(conf)][extraMember]:
                                        channel_mappings[str(conf)][extraMember].append(extraParent)
                                else:
                                    channel_mappings[str(conf)][extraMember] = [extraParent]

        # Try to impute equivalences between configurations
        count = 0
        for parent, group in gdiff.items():
            equivalent_confs[str(conf)].append([parent])

            for item, results in group.items():
                parentArray = results["parent"]
                replacements = [{ "eq": parent, "replacements": [] }]
                next = replacements
                acum = []

                for parentExtra in parentArray:
                    replacements = next
                    if parentExtra in channel_mappings[str(conf)]:
                        for toReplace in channel_mappings[str(conf)][parentExtra]:
                            next = []
                            for step in replacements:
                                replaced = step["eq"].replace(parentExtra, toReplace)

                                if replaced == item:
                                    equivalent_confs[str(conf)][count].append({"eq": item, "replacements": step["replacements"] + [{ parentExtra: toReplace }] })
                                    found = True
                                else: 
                                    next.append({"eq": replaced, "replacements": step["replacements"] + [{ parentExtra: toReplace }]})
                    #else:
                    #    break
            count += 1

        outfile.writelines([f"Configurations for {conf} channels ({len(df[df['count'] == conf]['channels'].unique())}), common_channels ({len(common)}): {json.dumps(common, indent=4)}", "\n"])
        
        # Channel frequency study
        frequency = {}
        for chans in channels:
            for channel in chans.split("|"):
                try:
                    frequency[channel] += 1
                except KeyError:
                    frequency[channel] = 1

        frequencies[conf] = {
            'total': len(channels),
            'frequency': frequency
        }

        for chann, freq in frequencies[conf]['frequency'].items():
            outfile.writelines([f'Frequency for channel "{chann}" for configuration {conf}: {(freq/frequencies[conf]['total']) * 100}%', "\n"])
        
        outfile.writelines([f'MEANINGFUL CHANNELS FOR CONF {conf}: \n'])
        count = 0
        for chann, freq in frequencies[conf]['frequency'].items():
            if freq/frequencies[conf]['total'] > (CHANNEL_FREQUENCY_THRESHOLD / 100):
                count += 1
                outfile.writelines([f'"{chann}"', "\n"])
                
        outfile.writelines([f'COUNT: {count}', '\n', '\n'])

    # Get the most seen configurations in the dataset, taking into account "equivalent" configurations
    groups = {}
    count = 0
    for confStr, equivalences in equivalent_confs.items():
        conf = int(confStr)
        groups[confStr] = []
        
        for group in equivalences:
            batch = []
            for equivalence in group:
                if isinstance(equivalence, dict):
                    batch.append(equivalence["eq"])
                else:
                    batch.append(equivalence)
            
            if len(batch) > 1:
                groups[confStr].append(batch)

        for batch in groups[confStr]:
            if df[df['channels'].isin(batch)].count()['channels'] / df[df['count'] == conf].count()['channels'] > CONF_CONTRIBUTION_THRESHOLD:
                outfile.writelines([f"Configuration ({conf}) {batch[0].ljust(600)}: {df[df['channels'].isin(batch)].count()["channels"]} ({(df[df['channels'].isin(batch)].count()['channels'] / df[df['count'] == conf].count()['channels']) * 100}%)", "\n"])
                count += df[df['channels'].isin(batch)].count()["channels"]

        channels = df[df['count'] == conf]['channels'].unique()
        for channs in channels:
            found = False
            for batch in groups[confStr]:
                if channs in batch:
                    found = True
                    break
            if not found:
                if df[df['channels'] == channs].count()['channels'] / df[df['count'] == conf].count()['channels'] > CONF_CONTRIBUTION_THRESHOLD:
                    outfile.writelines([f"Configuration ({conf}!) {channs.ljust(600)}: {df[df['channels'] == channs].count()["channels"]} ({(df[df['channels'] == channs].count()['channels'] / df[df['count'] == conf].count()['channels']) * 100}%)", "\n"])
                    count += df[df['channels'] == channs].count()["channels"]

    outfile.writelines([f'Representation ({count}): {(count / df.shape[0]) * 100}%'])

    # Dump equivalences to a json file
    with open("equivalences.json", "w") as jsonFile: 
        jsonFile.writelines(json.dumps(equivalent_confs, indent=4))

    # Aggregate channel equivalences
    aggregated_equivalences = []
    for conf, equivalences in equivalent_confs.items():
        for equivalence in equivalences:
            for group in equivalence:
                if isinstance(group, dict):
                    for replacement in group["replacements"]:
                        for key, value in replacement.items():

                            keyFound = False
                            valueFound = False

                            for present in aggregated_equivalences:
                                if key in present:
                                    keyFound = present
                                if value in present:
                                    valueFound = present

                            if not keyFound and not valueFound:
                                aggregated_equivalences.append([key, value])
                            elif valueFound:
                                if not key in valueFound:
                                    valueFound.append(key)
                            elif keyFound:
                                if not value in keyFound:
                                    keyFound.append(value)

    agg_eq = []
    for group in aggregated_equivalences:
        found = False
        for groupInner in aggregated_equivalences:
            if group != groupInner:
                intersection = set(group).intersection(set(groupInner))

                if intersection:
                    if not found:
                        found = [groupInner]
                    else:
                        found.append(groupInner)

        if found:
            merged = set(group) 
            for toMerge in found:
                merged = merged.union(set(toMerge))

            ls = list(merged)
            ls.sort()

            exists = False
            for agg in agg_eq:
                if agg == ls:
                    exists = True

            if not exists:
                agg_eq.append(ls)
        else:
            group.sort()
            agg_eq.append(group)

    # Aggregate channel frequencies for all the configurations
    outfile.writelines(['\n', '\n', 'AGGREGATED FREQUENCIES:', '\n', '\n'])

    aggregated = {}
    total = 0
    total_freqs = {}

    for conf, freqs in frequencies.items():
        total += freqs['total']

    for conf, freqs in frequencies.items():
        for chann, freq in freqs['frequency'].items():
            try:
                aggregated[chann] += freq
            except KeyError:
                aggregated[chann] = freq

    for chann, freq in aggregated.items():
        total_freqs[chann] = (freq/total) * 100
        outfile.writelines([f'Frequency for channel "{chann}": {(freq/total) * 100}%', '\n'])

    totals = pd.DataFrame(total_freqs.items(), columns=["channel", 'frequency'])
    outfile.writelines([f"\nChannels ({totals['channel'].count()})\n {totals[totals['frequency'] > CHANNEL_FREQUENCY_THRESHOLD]}"])

    # Aggregate channel frequencies taking into account channel equivalences
    outfile.writelines(['\n', '\n', 'AGGREGATED FREQUENCIES WITH EQUIVALENCES:', '\n', '\n'])
    valid_equiv = []
    freq_equiv = {}
    for chann in aggregated.keys():
        # Look for an equivalence group
        found = False

        for equivalence_group in agg_eq:
            if chann in equivalence_group:
                found = equivalence_group
        
        if found:
            channel_frequency = totals.loc[totals['channel'].isin(found), 'frequency'].sum()

            if channel_frequency > 70:
               exists = False
               for valid in valid_equiv:
                   if valid == found:
                       exists = True

               if not exists:
                valid_equiv.append(found)

            for c in found:
                freq_equiv[c] = channel_frequency

        else:
            channel_frequency = totals.loc[totals['channel'] == chann, 'frequency'].iloc[0]
            freq_equiv[chann] = channel_frequency

    totals_with_eq = pd.DataFrame(freq_equiv.items(), columns=["channel", 'frequency'])
    outfile.writelines([f"\nChannels ({totals_with_eq['channel'].count()})\n {totals_with_eq[totals_with_eq['frequency'] > CHANNEL_FREQUENCY_THRESHOLD]}"])

    outfile.writelines(['\n', '\n', 'EQUIVALENCES:', '\n', '\n'])
    outfile.writelines(json.dumps(agg_eq, indent=4))
    outfile.writelines(['\nUSED EQUIVALENCES:', '\n', '\n'])
    outfile.writelines(json.dumps(valid_equiv, indent=4))




    

